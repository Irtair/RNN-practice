{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c922548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "path = \"./configs/config.yaml\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b99648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞/–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n",
      "--–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import process_data\n",
    "\n",
    "cleaned = process_data(config[\"data\"][\"data_dir\"], config[\"data\"][\"raw_path\"], config[\"data\"][\"processed_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f2ac0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä —É–∂–µ –ø—Ä–æ—à–µ–ª —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É\n"
     ]
    }
   ],
   "source": [
    "from src.tokenizer import train_tokenizer\n",
    "\n",
    "train_tokenizer(config[\"data\"][\"processed_path\"], config[\"data\"][\"tokenizer_file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import data_tokenization\n",
    "\n",
    "tokenized = data_tokenization(config[\"data\"][\"data_dir\"], config[\"data\"][\"tokenized_file_name\"], cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8930fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train: 1277520, Val: 159690, Test: 159691\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import data_split\n",
    "\n",
    "train_seqs, val_seqs, test_seqs = data_split(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f2814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import TweeterDataset\n",
    "\n",
    "train_dataset = TweeterDataset(train_seqs)\n",
    "val_dataset = TweeterDataset(val_seqs)\n",
    "test_dataset = TweeterDataset(test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f72ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data_utils import collate_fn\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"data\"][\"train_batch_size\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"data\"][\"val_batch_size\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"data\"][\"test_batch_size\"],\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lstm_train import training, validation, evaluate_rouge_on_val, generate\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(config[\"data\"][\"tokenizer_file_name\"])\n",
    "\n",
    "num_epochs = config[\"training\"][\"epochs\"]\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"–≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    training(train_dataloader)\n",
    "    should_stop = validation(val_dataloader)\n",
    "    if should_stop: break\n",
    "\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        evaluate_rouge_on_val(test_dataloader, tokenizer)\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0 or epoch == 0:\n",
    "        generate(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d0741c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7f570d42f1f0>>' ‚Üí still dont know what to do\n"
     ]
    }
   ],
   "source": [
    "from src.eval_lstm import lsmt_generate\n",
    "prompt = \"still dont know\"\n",
    "lsmt_generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8755a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76/76 [00:00<00:00, 595.35it/s, Materializing param=transformer.wte.weight]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n",
      "1) I am about to be released by the company.‚Äù  The first episode of the series is called ÔøΩ\n",
      "2) What is going on with this, and what do you think this is going to be?\n",
      "3) Don't you mind if I'm on the phone with you?     If you're ready, ask my\n",
      "4) Let us deal with the question: Who exactly does the money come from?    So, even if we\n",
      "5) Deep Learning is a tool for learning new concepts. These resources are available as a single sheet of data. Each sheet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 486/486 [00:09<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0497\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from src.eval_transformer_pipeline import transformer_generate\n",
    "from src.eval_transformer_pipeline import rouge_calc_for_transformer\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞\n",
    "generation_prompts = [\"I am about\", \"What is going on with\", \"Don't you mind if\", \"Let us deal with\", \"Deep Learning is\"]\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "transformer_generate(generator, generation_prompts)\n",
    "rouge_calc_for_transformer(generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
